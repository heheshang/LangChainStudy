{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_community.chat_models import QianfanChatEndpoint\n",
    "from langchain_core.language_models.chat_models import HumanMessage\n",
    "\n",
    "os.environ[\"QIANFAN_AK\"] = \"LU4ZTVJKFROUZMJzA0biqqmC\"\n",
    "os.environ[\"QIANFAN_SK\"] = \"YHJ33uMEoH4HNTQGdthdGk07fyMW1DbR\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install qianfan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai chromadb tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!  pip install pysqlite3 -U --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = QianfanChatEndpoint(streaming=True,model=\"ERNIE-4.0-8K\")\n",
    "messages = [HumanMessage(content=\"你好\")]\n",
    "chat.invoke(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await chat.ainvoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat.batch([messages])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    for chunk in chat.stream(messages):\n",
    "        print(chunk.content, end=\"\", flush=True)\n",
    "except TypeError as e:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import QianfanLLMEndpoint\n",
    "llm = QianfanLLMEndpoint(streaming=True,model=\"ERNIE-4.0-8k\")\n",
    "res = llm.invoke(\"hi\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test for llm generate \"\"\"\n",
    "res = llm.generate(prompts=[\"hillo?\"])\n",
    "\"\"\"Test for llm aio generate\"\"\"\n",
    "\n",
    "\n",
    "async def run_aio_generate():\n",
    "    resp = await llm.agenerate(prompts=[\"Write a 20-word article about rivers.\"])\n",
    "    print(resp)\n",
    "\n",
    "\n",
    "await run_aio_generate()\n",
    "\n",
    "\"\"\"Test for llm stream\"\"\"\n",
    "for res in llm.stream(\"write a joke.\"):\n",
    "    print(res)\n",
    "\n",
    "\"\"\"Test for llm aio stream\"\"\"\n",
    "\n",
    "\n",
    "async def run_aio_stream():\n",
    "    async for res in llm.astream(\"Write a 20-word article about mountains\"):\n",
    "        print(res)\n",
    "\n",
    "\n",
    "await run_aio_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = QianfanLLMEndpoint(\n",
    "    streaming=True,\n",
    "    model=\"ERNIE-4.0-8k\",\n",
    ")\n",
    "res = llm.invoke(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = llm.generate(\n",
    "    prompts=[\"hi\"],\n",
    "    streaming=True,\n",
    "    **{\"top_p\": 0.4, \"temperature\": 0.1, \"penalty_score\": 1},\n",
    ")\n",
    "print(\"===========================\")\n",
    "\n",
    "for r in res:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install pymochow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade --quiet  clickhouse-connect\n",
    "! pip install chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import  Chroma\n",
    "from chromadb.config import Settings\n",
    "from langchain_community.embeddings import QianfanEmbeddingsEndpoint\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"QIANFAN_AK\"] = \"LU4ZTVJKFROUZMJzA0biqqmC\"\n",
    "os.environ[\"QIANFAN_SK\"] = \"YHJ33uMEoH4HNTQGdthdGk07fyMW1DbR\"\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"D:\\soft\\workspace\\pythonworkspace\\LangChainStudy\\documentstore\\state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = QianfanEmbeddingsEndpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!    pip install --upgrade pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in docs:\n",
    "    d.metadata = {\"some\": \"metadata\"}\n",
    "settings = Settings(\n",
    ")\n",
    "settings.chroma_server_host = \"pt001\"\n",
    "settings.chroma_server_http_port = 58000\n",
    "# from chromadb import HttpClient\n",
    "# client = HttpClient(host=\"pt001\", port=58000)\n",
    "docsearch =  Chroma.from_documents(docs, embeddings, client_settings=settings)\n",
    "query = \"*\"\n",
    "\n",
    "docs =  docsearch.similarity_search(query)\n",
    "print(type(docs))\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(docsearch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(docsearch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
